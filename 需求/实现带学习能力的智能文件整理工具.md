# Filo - æ–‡ä»¶æ™ºç† å®Œæ•´è®¾è®¡æ–¹æ¡ˆ

## ä¸€ã€å“ç‰Œè®¾è®¡

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                           â•‘
â•‘     â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—                                          â•‘
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘                                          â•‘
â•‘     â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘                                          â•‘
â•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•                                          â•‘
â•‘     â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â•                                           â•‘
â•‘                                                                           â•‘
â•‘     File Intelligent Logic Organizer                                      â•‘
â•‘                                                                           â•‘
â•‘     æ–‡ä»¶æ™ºç† Â· è¶Šç”¨è¶Šæ‡‚ä½                                                   â•‘
â•‘     The more you use, the smarter it gets                                 â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ ¸å¿ƒç‰¹æ€§                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ§  æœ¬åœ°AI    ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ï¼Œæ•°æ®ä¸å‡ºé—¨ï¼Œéšç§æœ‰ä¿éšœ              â”‚
â”‚  ğŸ“š æ™ºèƒ½å­¦ä¹   è‡ªåŠ¨è®°ä½ä½ çš„æ•´ç†ä¹ æƒ¯ï¼Œè¶Šç”¨è¶Šç²¾å‡†                    â”‚
â”‚  ğŸš€ æé€Ÿå“åº”  ç›¸ä¼¼æ–‡ä»¶æ¯«ç§’çº§è¯†åˆ«ï¼Œå‘Šåˆ«é‡å¤ç­‰å¾…                    â”‚
â”‚  ğŸ¯ ç²¾å‡†åˆ†ç±»  ç†è§£æ–‡ä»¶è¯­ä¹‰ï¼Œä¸æ­¢çœ‹æ‰©å±•å                          â”‚
â”‚  ğŸ’¡ äº¤äº’çº é”™  ä¸æ»¡æ„å¯ä¿®æ­£ï¼Œç³»ç»Ÿç«‹å³å­¦ä¼š                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€é¡¹ç›®ç»“æ„

```
filo/
â”œâ”€â”€ main.go                      # ç¨‹åºå…¥å£
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ root.go                  # ä¸»å‘½ä»¤ï¼ˆæ•´ç†ï¼‰
â”‚   â”œâ”€â”€ setup.go                 # å®‰è£…å‘å¯¼
â”‚   â”œâ”€â”€ stats.go                 # å­¦ä¹ ç»Ÿè®¡
â”‚   â”œâ”€â”€ scan.go                  # æ–‡ä»¶æ‰«æ
â”‚   â”œâ”€â”€ models.go                # æ¨¡å‹ç®¡ç†
â”‚   â”œâ”€â”€ reset.go                 # é‡ç½®æ•°æ®
â”‚   â””â”€â”€ version.go               # ç‰ˆæœ¬ä¿¡æ¯
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.go            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ ollama.go            # Ollama API
â”‚   â”œâ”€â”€ embedding/
â”‚   â”‚   â””â”€â”€ embedding.go         # å‘é‡åµŒå…¥
â”‚   â”œâ”€â”€ scanner/
â”‚   â”‚   â””â”€â”€ scanner.go           # æ–‡ä»¶æ‰«æ
â”‚   â”œâ”€â”€ classifier/
â”‚   â”‚   â””â”€â”€ classifier.go        # æ™ºèƒ½åˆ†ç±»
â”‚   â”œâ”€â”€ organizer/
â”‚   â”‚   â””â”€â”€ organizer.go         # æ–‡ä»¶æ•´ç†
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ memory.go            # è®°å¿†ç³»ç»Ÿ
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ database.go          # æ•°æ®å­˜å‚¨
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ ui.go                # ç»ˆç«¯ç•Œé¢
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ Makefile
â”œâ”€â”€ install.sh                   # ä¸€é”®å®‰è£…è„šæœ¬
â””â”€â”€ README.md
```

---

## ä¸‰ã€å®Œæ•´ä»£ç 

### `go.mod`

```go
module filo

go 1.21

require (
	github.com/fatih/color v1.16.0
	github.com/schollz/progressbar/v3 v3.14.1
	github.com/spf13/cobra v1.8.0
	modernc.org/sqlite v1.28.0
)

require (
	github.com/dustin/go-humanize v1.0.1 // indirect
	github.com/google/uuid v1.5.0 // indirect
	github.com/hashicorp/golang-lru/v2 v2.0.7 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/mattn/go-colorable v0.1.13 // indirect
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/mitchellh/colorstring v0.0.0-20190213212951-d06e56a500db // indirect
	github.com/ncruces/go-strftime v0.1.9 // indirect
	github.com/remyoudompheng/bigfft v0.0.0-20230129092748-24d4a6f8daec // indirect
	github.com/rivo/uniseg v0.4.4 // indirect
	github.com/spf13/pflag v1.0.5 // indirect
	golang.org/x/sys v0.15.0 // indirect
	golang.org/x/term v0.15.0 // indirect
	modernc.org/gc/v3 v3.0.0-20240107210532-573471604cb6 // indirect
	modernc.org/libc v1.41.0 // indirect
	modernc.org/mathutil v1.6.0 // indirect
	modernc.org/memory v1.7.2 // indirect
	modernc.org/strutil v1.2.0 // indirect
	modernc.org/token v1.1.0 // indirect
)
```

### `main.go`

```go
package main

import "filo/cmd"

func main() {
	cmd.Execute()
}
```

### `internal/config/config.go`

```go
package config

import (
	"encoding/json"
	"os"
	"path/filepath"
	"sync"
)

// Version ç‰ˆæœ¬ä¿¡æ¯
const (
	Version   = "2.0.0"
	BuildDate = "2024"
)

// Config å…¨å±€é…ç½®
type Config struct {
	// æ¨¡å‹é…ç½®
	LLMModel       string  `json:"llm_model"`
	EmbeddingModel string  `json:"embedding_model"`
	OllamaURL      string  `json:"ollama_url"`
	Temperature    float64 `json:"temperature"`
	MaxTokens      int     `json:"max_tokens"`

	// å­¦ä¹ é…ç½®
	EnableLearning      bool    `json:"enable_learning"`
	SimilarityThreshold float64 `json:"similarity_threshold"`
	ConfidenceThreshold float64 `json:"confidence_threshold"`
	MinSamplesForRule   int     `json:"min_samples_for_rule"`

	// å¤„ç†é…ç½®
	BatchSize int `json:"batch_size"`

	// è·¯å¾„ï¼ˆä¸åºåˆ—åŒ–ï¼‰
	DataDir string `json:"-"`
	DBPath  string `json:"-"`
}

var (
	instance *Config
	once     sync.Once
)

// Get è·å–å…¨å±€é…ç½®å®ä¾‹
func Get() *Config {
	once.Do(func() {
		instance = defaultConfig()
		instance.initPaths()
		instance.Load()
	})
	return instance
}

func defaultConfig() *Config {
	return &Config{
		LLMModel:            "qwen2.5:7b",
		EmbeddingModel:      "nomic-embed-text",
		OllamaURL:           "http://localhost:11434",
		Temperature:         0.3,
		MaxTokens:           2048,
		EnableLearning:      true,
		SimilarityThreshold: 0.85,
		ConfidenceThreshold: 0.7,
		MinSamplesForRule:   3,
		BatchSize:           15,
	}
}

func (c *Config) initPaths() {
	homeDir, _ := os.UserHomeDir()
	c.DataDir = filepath.Join(homeDir, ".filo")
	c.DBPath = filepath.Join(c.DataDir, "memory.db")
	os.MkdirAll(c.DataDir, 0755)
}

// Load ä»æ–‡ä»¶åŠ è½½é…ç½®
func (c *Config) Load() error {
	configPath := filepath.Join(c.DataDir, "config.json")
	data, err := os.ReadFile(configPath)
	if err != nil {
		return err
	}
	return json.Unmarshal(data, c)
}

// Save ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
func (c *Config) Save() error {
	configPath := filepath.Join(c.DataDir, "config.json")
	data, err := json.MarshalIndent(c, "", "  ")
	if err != nil {
		return err
	}
	return os.WriteFile(configPath, data, 0644)
}

// SetModel è®¾ç½®æ¨¡å‹
func (c *Config) SetModel(model string) {
	c.LLMModel = model
}
```

### `internal/ui/ui.go`

```go
package ui

import (
	"fmt"
	"strings"

	"github.com/fatih/color"
)

var (
	Cyan    = color.New(color.FgCyan).SprintFunc()
	Green   = color.New(color.FgGreen).SprintFunc()
	Yellow  = color.New(color.FgYellow).SprintFunc()
	Red     = color.New(color.FgRed).SprintFunc()
	White   = color.New(color.FgWhite).SprintFunc()
	Gray    = color.New(color.FgHiBlack).SprintFunc()
	Bold    = color.New(color.Bold).SprintFunc()
	BoldCyan = color.New(color.FgCyan, color.Bold).SprintFunc()
)

// Banner æ‰“å°å¯åŠ¨æ¨ªå¹…
func Banner() {
	banner := `
` + Cyan(`  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— `) + `
` + Cyan(`  â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—`) + `
` + Cyan(`  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘`) + `
` + Cyan(`  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘`) + `
` + Cyan(`  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•`) + `
` + Cyan(`  â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• `) + `
` + Gray(`  æ–‡ä»¶æ™ºç† Â· è¶Šç”¨è¶Šæ‡‚ä½ `) + ` ` + Gray(`v2.0`) + `
`
	fmt.Println(banner)
}

// Title æ‰“å°æ ‡é¢˜
func Title(icon, text string) {
	fmt.Printf("\n%s %s\n", icon, BoldCyan(text))
}

// Success æˆåŠŸæ¶ˆæ¯
func Success(format string, args ...interface{}) {
	fmt.Printf("  %s %s\n", Green("âœ“"), fmt.Sprintf(format, args...))
}

// Error é”™è¯¯æ¶ˆæ¯
func Error(format string, args ...interface{}) {
	fmt.Printf("  %s %s\n", Red("âœ—"), fmt.Sprintf(format, args...))
}

// Warning è­¦å‘Šæ¶ˆæ¯
func Warning(format string, args ...interface{}) {
	fmt.Printf("  %s %s\n", Yellow("âš "), fmt.Sprintf(format, args...))
}

// Info ä¿¡æ¯æ¶ˆæ¯
func Info(format string, args ...interface{}) {
	fmt.Printf("  %s\n", fmt.Sprintf(format, args...))
}

// Dim æš—è‰²æ¶ˆæ¯
func Dim(format string, args ...interface{}) {
	fmt.Printf("  %s\n", Gray(fmt.Sprintf(format, args...)))
}

// Divider åˆ†éš”çº¿
func Divider() {
	fmt.Println(Gray(strings.Repeat("â”€", 55)))
}

// Box ç»˜åˆ¶æ–¹æ¡†
func Box(title string, lines []string) {
	width := 55
	fmt.Println(Cyan("â•­" + strings.Repeat("â”€", width-2) + "â•®"))
	
	// æ ‡é¢˜
	titlePadding := (width - 4 - len(title)) / 2
	fmt.Printf("%s%s%s%s%s\n", 
		Cyan("â”‚"), 
		strings.Repeat(" ", titlePadding),
		Bold(title),
		strings.Repeat(" ", width-4-titlePadding-len(title)),
		Cyan("â”‚"))
	
	fmt.Println(Cyan("â”œ" + strings.Repeat("â”€", width-2) + "â”¤"))
	
	// å†…å®¹
	for _, line := range lines {
		padding := width - 4 - displayWidth(line)
		if padding < 0 {
			padding = 0
		}
		fmt.Printf("%s %s%s%s\n", Cyan("â”‚"), line, strings.Repeat(" ", padding), Cyan("â”‚"))
	}
	
	fmt.Println(Cyan("â•°" + strings.Repeat("â”€", width-2) + "â•¯"))
}

// displayWidth è®¡ç®—æ˜¾ç¤ºå®½åº¦ï¼ˆå¤„ç†ä¸­æ–‡ï¼‰
func displayWidth(s string) int {
	width := 0
	for _, r := range s {
		if r > 127 {
			width += 2
		} else {
			width += 1
		}
	}
	return width
}

// SourceIcon è·å–æ¥æºå›¾æ ‡
func SourceIcon(source string) string {
	switch source {
	case "memory":
		return "ğŸ§ "
	case "llm":
		return "ğŸ¤–"
	case "rule":
		return "ğŸ“‹"
	default:
		return "â“"
	}
}

// ConfidenceIcon è·å–ç½®ä¿¡åº¦å›¾æ ‡
func ConfidenceIcon(confidence float64) string {
	if confidence >= 0.8 {
		return Green("âœ“")
	} else if confidence >= 0.5 {
		return Yellow("â—")
	}
	return Red("â—‹")
}

// FormatSize æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
func FormatSize(size int64) string {
	const (
		KB = 1024
		MB = KB * 1024
		GB = MB * 1024
	)
	switch {
	case size >= GB:
		return fmt.Sprintf("%.1f GB", float64(size)/GB)
	case size >= MB:
		return fmt.Sprintf("%.1f MB", float64(size)/MB)
	case size >= KB:
		return fmt.Sprintf("%.1f KB", float64(size)/KB)
	default:
		return fmt.Sprintf("%d B", size)
	}
}
```

### `internal/storage/database.go`

```go
package storage

import (
	"database/sql"
	"encoding/json"
	"strings"
	"time"

	_ "modernc.org/sqlite"

	"filo/internal/config"
)

// Database æ•°æ®åº“ç®¡ç†
type Database struct {
	db *sql.DB
}

// ClassificationRecord åˆ†ç±»è®°å½•
type ClassificationRecord struct {
	ID            int64
	Filename      string
	Extension     string
	Category      string
	Subcategory   string
	Confidence    float64
	Keywords      []string
	UserConfirmed bool
	CreatedAt     time.Time
}

// LearnedRule å­¦ä¹ åˆ°çš„è§„åˆ™
type LearnedRule struct {
	ID          int64
	Pattern     string
	PatternType string // keyword, extension, prefix
	Category    string
	Subcategory string
	Priority    int
	HitCount    int
	SuccessRate float64
}

// NewDatabase åˆ›å»ºæ•°æ®åº“è¿æ¥
func NewDatabase() (*Database, error) {
	cfg := config.Get()
	db, err := sql.Open("sqlite", cfg.DBPath)
	if err != nil {
		return nil, err
	}

	// å¯ç”¨ WAL æ¨¡å¼æå‡æ€§èƒ½
	db.Exec("PRAGMA journal_mode=WAL")
	db.Exec("PRAGMA synchronous=NORMAL")

	d := &Database{db: db}
	if err := d.init(); err != nil {
		return nil, err
	}
	return d, nil
}

func (d *Database) init() error {
	schemas := []string{
		// åˆ†ç±»å†å²è¡¨
		`CREATE TABLE IF NOT EXISTS classification_history (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			filename TEXT NOT NULL,
			extension TEXT DEFAULT '',
			category TEXT NOT NULL,
			subcategory TEXT DEFAULT '',
			confidence REAL DEFAULT 0.5,
			keywords TEXT DEFAULT '[]',
			user_confirmed INTEGER DEFAULT 0,
			source TEXT DEFAULT 'llm',
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
		)`,
		// å­¦ä¹ è§„åˆ™è¡¨
		`CREATE TABLE IF NOT EXISTS learned_rules (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			pattern TEXT NOT NULL,
			pattern_type TEXT DEFAULT 'keyword',
			category TEXT NOT NULL,
			subcategory TEXT DEFAULT '',
			priority INTEGER DEFAULT 0,
			hit_count INTEGER DEFAULT 0,
			success_count INTEGER DEFAULT 0,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
			updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
			UNIQUE(pattern, pattern_type, category)
		)`,
		// ç”¨æˆ·åé¦ˆè¡¨
		`CREATE TABLE IF NOT EXISTS user_feedback (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			filename TEXT NOT NULL,
			original_category TEXT,
			corrected_category TEXT NOT NULL,
			original_subcategory TEXT DEFAULT '',
			corrected_subcategory TEXT DEFAULT '',
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
		)`,
		// å‘é‡å­˜å‚¨è¡¨
		`CREATE TABLE IF NOT EXISTS vectors (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			filename TEXT NOT NULL,
			category TEXT NOT NULL,
			subcategory TEXT DEFAULT '',
			vector BLOB NOT NULL,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
		)`,
		// ç´¢å¼•
		`CREATE INDEX IF NOT EXISTS idx_history_filename ON classification_history(filename)`,
		`CREATE INDEX IF NOT EXISTS idx_history_category ON classification_history(category)`,
		`CREATE INDEX IF NOT EXISTS idx_history_confirmed ON classification_history(user_confirmed)`,
		`CREATE INDEX IF NOT EXISTS idx_rules_pattern ON learned_rules(pattern)`,
		`CREATE INDEX IF NOT EXISTS idx_rules_category ON learned_rules(category)`,
	}

	for _, schema := range schemas {
		if _, err := d.db.Exec(schema); err != nil {
			return err
		}
	}
	return nil
}

// Close å…³é—­æ•°æ®åº“è¿æ¥
func (d *Database) Close() error {
	return d.db.Close()
}

// ==================== åˆ†ç±»å†å²æ“ä½œ ====================

// AddClassification æ·»åŠ åˆ†ç±»è®°å½•
func (d *Database) AddClassification(filename, ext, category, subcategory, source string, confidence float64, keywords []string, confirmed bool) (int64, error) {
	kw, _ := json.Marshal(keywords)
	result, err := d.db.Exec(`
		INSERT INTO classification_history (filename, extension, category, subcategory, confidence, keywords, user_confirmed, source)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?)
	`, filename, ext, category, subcategory, confidence, string(kw), confirmed, source)
	if err != nil {
		return 0, err
	}
	return result.LastInsertId()
}

// GetSimilarClassifications è·å–ç›¸ä¼¼çš„å†å²åˆ†ç±»
func (d *Database) GetSimilarClassifications(keywords []string, limit int) ([]ClassificationRecord, error) {
	if len(keywords) == 0 {
		return nil, nil
	}

	// æ„å»ºæŸ¥è¯¢
	conditions := make([]string, 0, len(keywords))
	args := make([]interface{}, 0, len(keywords)+1)
	for _, kw := range keywords {
		if len(kw) >= 2 {
			conditions = append(conditions, "LOWER(filename) LIKE ?")
			args = append(args, "%"+strings.ToLower(kw)+"%")
		}
	}

	if len(conditions) == 0 {
		return nil, nil
	}

	query := `
		SELECT id, filename, extension, category, subcategory, confidence, keywords, user_confirmed, created_at
		FROM classification_history
		WHERE user_confirmed = 1 AND (` + strings.Join(conditions, " OR ") + `)
		ORDER BY created_at DESC
		LIMIT ?
	`
	args = append(args, limit)

	rows, err := d.db.Query(query, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var records []ClassificationRecord
	for rows.Next() {
		var r ClassificationRecord
		var kwJSON, createdAt string
		if err := rows.Scan(&r.ID, &r.Filename, &r.Extension, &r.Category, &r.Subcategory, &r.Confidence, &kwJSON, &r.UserConfirmed, &createdAt); err != nil {
			continue
		}
		json.Unmarshal([]byte(kwJSON), &r.Keywords)
		r.CreatedAt, _ = time.Parse("2006-01-02 15:04:05", createdAt)
		records = append(records, r)
	}
	return records, nil
}

// ConfirmClassification ç¡®è®¤åˆ†ç±»
func (d *Database) ConfirmClassification(id int64) error {
	_, err := d.db.Exec("UPDATE classification_history SET user_confirmed = 1 WHERE id = ?", id)
	return err
}

// ==================== è§„åˆ™æ“ä½œ ====================

// AddOrUpdateRule æ·»åŠ æˆ–æ›´æ–°è§„åˆ™
func (d *Database) AddOrUpdateRule(pattern, patternType, category, subcategory string, priority int) error {
	pattern = strings.ToLower(pattern)

	// å°è¯•æ›´æ–°å·²æœ‰è§„åˆ™
	result, err := d.db.Exec(`
		UPDATE learned_rules 
		SET hit_count = hit_count + 1, 
		    priority = MAX(priority, ?),
		    updated_at = CURRENT_TIMESTAMP
		WHERE pattern = ? AND pattern_type = ? AND category = ?
	`, priority, pattern, patternType, category)

	if err != nil {
		return err
	}

	affected, _ := result.RowsAffected()
	if affected == 0 {
		// æ’å…¥æ–°è§„åˆ™
		_, err = d.db.Exec(`
			INSERT INTO learned_rules (pattern, pattern_type, category, subcategory, priority, hit_count)
			VALUES (?, ?, ?, ?, ?, 1)
		`, pattern, patternType, category, subcategory, priority)
	}
	return err
}

// GetMatchingRules è·å–åŒ¹é…çš„è§„åˆ™
func (d *Database) GetMatchingRules(filename string, keywords []string, ext string) ([]LearnedRule, error) {
	var rules []LearnedRule
	filename = strings.ToLower(filename)
	ext = strings.ToLower(ext)

	// æ‰©å±•ååŒ¹é…
	if ext != "" {
		rows, _ := d.db.Query(`
			SELECT id, pattern, pattern_type, category, subcategory, priority, hit_count
			FROM learned_rules 
			WHERE pattern_type = 'extension' AND pattern = ?
			ORDER BY priority DESC, hit_count DESC
			LIMIT 3
		`, ext)
		if rows != nil {
			rules = append(rules, d.scanRules(rows)...)
			rows.Close()
		}
	}

	// å…³é”®è¯åŒ¹é…
	for _, kw := range keywords {
		if len(kw) < 2 {
			continue
		}
		rows, _ := d.db.Query(`
			SELECT id, pattern, pattern_type, category, subcategory, priority, hit_count
			FROM learned_rules 
			WHERE pattern_type = 'keyword' AND ? LIKE '%' || pattern || '%'
			ORDER BY priority DESC, hit_count DESC
			LIMIT 3
		`, filename)
		if rows != nil {
			rules = append(rules, d.scanRules(rows)...)
			rows.Close()
		}
	}

	// å»é‡
	seen := make(map[string]bool)
	unique := make([]LearnedRule, 0)
	for _, r := range rules {
		key := r.Pattern + "|" + r.Category
		if !seen[key] {
			seen[key] = true
			unique = append(unique, r)
		}
	}
	return unique, nil
}

func (d *Database) scanRules(rows *sql.Rows) []LearnedRule {
	var rules []LearnedRule
	for rows.Next() {
		var r LearnedRule
		if err := rows.Scan(&r.ID, &r.Pattern, &r.PatternType, &r.Category, &r.Subcategory, &r.Priority, &r.HitCount); err == nil {
			rules = append(rules, r)
		}
	}
	return rules
}

// GetTopRules è·å–æœ€å¸¸ç”¨çš„è§„åˆ™
func (d *Database) GetTopRules(limit int) ([]map[string]interface{}, error) {
	rows, err := d.db.Query(`
		SELECT pattern, pattern_type, category, subcategory, hit_count, priority
		FROM learned_rules
		WHERE hit_count >= 1
		ORDER BY hit_count DESC, priority DESC
		LIMIT ?
	`, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var rules []map[string]interface{}
	for rows.Next() {
		var pattern, ptype, cat, sub string
		var hitCount, priority int
		if rows.Scan(&pattern, &ptype, &cat, &sub, &hitCount, &priority) == nil {
			rules = append(rules, map[string]interface{}{
				"pattern":      pattern,
				"pattern_type": ptype,
				"category":     cat,
				"subcategory":  sub,
				"hit_count":    hitCount,
				"priority":     priority,
			})
		}
	}
	return rules, nil
}

// ==================== å‘é‡æ“ä½œ ====================

// SaveVector ä¿å­˜å‘é‡
func (d *Database) SaveVector(filename, category, subcategory string, vector []float64) error {
	vecJSON, _ := json.Marshal(vector)
	_, err := d.db.Exec(`
		INSERT INTO vectors (filename, category, subcategory, vector)
		VALUES (?, ?, ?, ?)
	`, filename, category, subcategory, vecJSON)
	return err
}

// SearchVectors æœç´¢å‘é‡
func (d *Database) SearchVectors(limit int) ([]struct {
	Filename    string
	Category    string
	Subcategory string
	Vector      []float64
}, error) {
	rows, err := d.db.Query(`
		SELECT filename, category, subcategory, vector
		FROM vectors
		ORDER BY created_at DESC
		LIMIT ?
	`, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var results []struct {
		Filename    string
		Category    string
		Subcategory string
		Vector      []float64
	}

	for rows.Next() {
		var r struct {
			Filename    string
			Category    string
			Subcategory string
			Vector      []float64
		}
		var vecJSON string
		if rows.Scan(&r.Filename, &r.Category, &r.Subcategory, &vecJSON) == nil {
			json.Unmarshal([]byte(vecJSON), &r.Vector)
			results = append(results, r)
		}
	}
	return results, nil
}

// ==================== åé¦ˆæ“ä½œ ====================

// AddFeedback æ·»åŠ ç”¨æˆ·åé¦ˆ
func (d *Database) AddFeedback(filename, origCat, corrCat, origSub, corrSub string) error {
	_, err := d.db.Exec(`
		INSERT INTO user_feedback (filename, original_category, corrected_category, original_subcategory, corrected_subcategory)
		VALUES (?, ?, ?, ?, ?)
	`, filename, origCat, corrCat, origSub, corrSub)
	return err
}

// ==================== ç»Ÿè®¡æ“ä½œ ====================

// GetStatistics è·å–ç»Ÿè®¡ä¿¡æ¯
func (d *Database) GetStatistics() (map[string]interface{}, error) {
	stats := make(map[string]interface{})

	// æ€»è®°å½•æ•°
	var total int
	d.db.QueryRow("SELECT COUNT(*) FROM classification_history").Scan(&total)
	stats["total_records"] = total

	// ç¡®è®¤æ•°
	var confirmed int
	d.db.QueryRow("SELECT COUNT(*) FROM classification_history WHERE user_confirmed = 1").Scan(&confirmed)
	stats["confirmed_records"] = confirmed

	// è§„åˆ™æ•°
	var rules int
	d.db.QueryRow("SELECT COUNT(*) FROM learned_rules WHERE hit_count > 0").Scan(&rules)
	stats["learned_rules"] = rules

	// å‘é‡æ•°
	var vectors int
	d.db.QueryRow("SELECT COUNT(*) FROM vectors").Scan(&vectors)
	stats["vector_count"] = vectors

	// åé¦ˆæ•°
	var feedback int
	d.db.QueryRow("SELECT COUNT(*) FROM user_feedback").Scan(&feedback)
	stats["feedback_count"] = feedback

	// åˆ†ç±»åˆ†å¸ƒ
	rows, _ := d.db.Query(`
		SELECT category, COUNT(*) as cnt 
		FROM classification_history 
		GROUP BY category 
		ORDER BY cnt DESC 
		LIMIT 10
	`)
	if rows != nil {
		defer rows.Close()
		dist := make(map[string]int)
		for rows.Next() {
			var cat string
			var cnt int
			if rows.Scan(&cat, &cnt) == nil {
				dist[cat] = cnt
			}
		}
		stats["category_distribution"] = dist
	}

	return stats, nil
}

// ==================== é‡ç½®æ“ä½œ ====================

// ResetHistory é‡ç½®å†å²
func (d *Database) ResetHistory() error {
	_, err := d.db.Exec("DELETE FROM classification_history")
	return err
}

// ResetRules é‡ç½®è§„åˆ™
func (d *Database) ResetRules() error {
	_, err := d.db.Exec("DELETE FROM learned_rules")
	return err
}

// ResetVectors é‡ç½®å‘é‡
func (d *Database) ResetVectors() error {
	_, err := d.db.Exec("DELETE FROM vectors")
	return err
}

// ResetAll é‡ç½®æ‰€æœ‰
func (d *Database) ResetAll() error {
	tables := []string{"classification_history", "learned_rules", "user_feedback", "vectors"}
	for _, t := range tables {
		if _, err := d.db.Exec("DELETE FROM " + t); err != nil {
			return err
		}
	}
	return nil
}
```

### `internal/llm/ollama.go`

```go
package llm

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"regexp"
	"time"

	"filo/internal/config"
)

// Client Ollama å®¢æˆ·ç«¯
type Client struct {
	baseURL    string
	model      string
	httpClient *http.Client
}

// ChatMessage èŠå¤©æ¶ˆæ¯
type ChatMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// NewClient åˆ›å»ºå®¢æˆ·ç«¯
func NewClient() *Client {
	cfg := config.Get()
	return &Client{
		baseURL: cfg.OllamaURL,
		model:   cfg.LLMModel,
		httpClient: &http.Client{
			Timeout: 180 * time.Second,
		},
	}
}

// IsAvailable æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
func (c *Client) IsAvailable() bool {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	req, _ := http.NewRequestWithContext(ctx, "GET", c.baseURL+"/api/tags", nil)
	resp, err := c.httpClient.Do(req)
	if err != nil {
		return false
	}
	defer resp.Body.Close()
	return resp.StatusCode == http.StatusOK
}

// HasModel æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
func (c *Client) HasModel(model string) bool {
	models, err := c.ListModels()
	if err != nil {
		return false
	}
	for _, m := range models {
		if m == model {
			return true
		}
	}
	return false
}

// ListModels åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
func (c *Client) ListModels() ([]string, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	req, _ := http.NewRequestWithContext(ctx, "GET", c.baseURL+"/api/tags", nil)
	resp, err := c.httpClient.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var result struct {
		Models []struct {
			Name string `json:"name"`
		} `json:"models"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, err
	}

	models := make([]string, len(result.Models))
	for i, m := range result.Models {
		models[i] = m.Name
	}
	return models, nil
}

// Chat å‘é€èŠå¤©è¯·æ±‚
func (c *Client) Chat(ctx context.Context, messages []ChatMessage, jsonMode bool) (string, error) {
	cfg := config.Get()

	payload := map[string]interface{}{
		"model":    c.model,
		"messages": messages,
		"stream":   false,
		"options": map[string]interface{}{
			"temperature": cfg.Temperature,
		},
	}

	if jsonMode {
		payload["format"] = "json"
	}

	body, _ := json.Marshal(payload)
	req, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/chat", bytes.NewReader(body))
	if err != nil {
		return "", err
	}
	req.Header.Set("Content-Type", "application/json")

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return "", fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("APIé”™è¯¯ %d: %s", resp.StatusCode, string(body))
	}

	var chatResp struct {
		Message ChatMessage `json:"message"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&chatResp); err != nil {
		return "", err
	}

	return chatResp.Message.Content, nil
}

// Embed è·å–æ–‡æœ¬åµŒå…¥
func (c *Client) Embed(ctx context.Context, text string) ([]float64, error) {
	cfg := config.Get()

	payload := map[string]string{
		"model":  cfg.EmbeddingModel,
		"prompt": text,
	}

	body, _ := json.Marshal(payload)
	req, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/embeddings", bytes.NewReader(body))
	if err != nil {
		return nil, err
	}
	req.Header.Set("Content-Type", "application/json")

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("åµŒå…¥APIé”™è¯¯: %d", resp.StatusCode)
	}

	var embResp struct {
		Embedding []float64 `json:"embedding"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&embResp); err != nil {
		return nil, err
	}

	return embResp.Embedding, nil
}

// ClassifyFiles æ‰¹é‡åˆ†ç±»æ–‡ä»¶
func (c *Client) ClassifyFiles(ctx context.Context, files []map[string]interface{}, rules []map[string]string) (map[string]interface{}, error) {
	systemPrompt := buildSystemPrompt(rules)
	userPrompt := buildUserPrompt(files)

	messages := []ChatMessage{
		{Role: "system", Content: systemPrompt},
		{Role: "user", Content: userPrompt},
	}

	response, err := c.Chat(ctx, messages, true)
	if err != nil {
		return nil, err
	}

	// è§£æ JSON
	var result map[string]interface{}
	if err := json.Unmarshal([]byte(response), &result); err != nil {
		// å°è¯•æå– JSON
		re := regexp.MustCompile(`\{[\s\S]*\}`)
		if match := re.FindString(response); match != "" {
			if err := json.Unmarshal([]byte(match), &result); err != nil {
				return nil, fmt.Errorf("è§£æå¤±è´¥: %w", err)
			}
		} else {
			return nil, fmt.Errorf("æ— æ³•è§£æå“åº”")
		}
	}

	return result, nil
}

func buildSystemPrompt(rules []map[string]string) string {
	prompt := `ä½ æ˜¯ä¸“ä¸šçš„æ–‡ä»¶åˆ†ç±»åŠ©æ‰‹ã€‚æ ¹æ®æ–‡ä»¶åæ™ºèƒ½åˆ†ç±»ï¼Œç†è§£æ–‡ä»¶çš„ç”¨é€”å’Œå«ä¹‰ã€‚

åˆ†ç±»åŸåˆ™ï¼š
1. æ ¹æ®æ–‡ä»¶åè¯­ä¹‰åˆ†ç±»ï¼Œä¸è¦ä»…çœ‹æ‰©å±•å
2. è¯†åˆ«é¡¹ç›®åã€å®¢æˆ·åã€ä¸šåŠ¡é¢†åŸŸ
3. æ³¨æ„æ—¥æœŸã€ç‰ˆæœ¬å·ã€å…³é”®è¯
4. ç›¸å…³æ–‡ä»¶å½’å…¥åŒä¸€ç±»åˆ«

å¸¸ç”¨åˆ†ç±»ï¼š
- æ–‡æ¡£ï¼šåˆåŒã€æŠ¥å‘Šã€æ–¹æ¡ˆã€ç¬”è®°ã€ç®€å†
- å›¾ç‰‡ï¼šç…§ç‰‡ã€æˆªå›¾ã€è®¾è®¡ç¨¿ã€å›¾æ ‡
- è§†é¢‘ï¼šç”µå½±ã€æ•™ç¨‹ã€å½•å±ã€ä¼šè®®
- éŸ³é¢‘ï¼šéŸ³ä¹ã€å½•éŸ³ã€æ’­å®¢
- ä»£ç ï¼šæºç ã€é…ç½®ã€è„šæœ¬
- å‹ç¼©åŒ…ï¼šå¤‡ä»½ã€èµ„æ–™åŒ…
- å®‰è£…åŒ…ï¼šè½¯ä»¶ã€å·¥å…·
- æ•°æ®ï¼šè¡¨æ ¼ã€æ•°æ®åº“ã€å¯¼å‡º

å¿…é¡»è¿”å›æœ‰æ•ˆJSONã€‚`

	if len(rules) > 0 {
		prompt += "\n\nå·²å­¦ä¹ çš„åˆ†ç±»è§„åˆ™ï¼ˆä¼˜å…ˆå‚è€ƒï¼‰ï¼š\n"
		for i, r := range rules {
			if i >= 20 {
				break
			}
			prompt += fmt.Sprintf("- ã€Œ%sã€â†’ %s/%s\n", r["pattern"], r["category"], r["subcategory"])
		}
	}

	return prompt
}

func buildUserPrompt(files []map[string]interface{}) string {
	filesJSON, _ := json.MarshalIndent(files, "", "  ")
	return fmt.Sprintf(`è¯·å¯¹ä»¥ä¸‹ %d ä¸ªæ–‡ä»¶è¿›è¡Œåˆ†ç±»ï¼š

%s

è¿”å›JSONæ ¼å¼ï¼š
{
  "classifications": [
    {
      "filename": "æ–‡ä»¶å",
      "category": "ä¸»åˆ†ç±»",
      "subcategory": "å­åˆ†ç±»",
      "confidence": 0.95,
      "reasoning": "åˆ†ç±»ç†ç”±",
      "keywords": ["å…³é”®è¯"]
    }
  ]
}`, len(files), string(filesJSON))
}
```

### `internal/embedding/embedding.go`

```go
package embedding

import (
	"context"
	"hash/fnv"
	"math"
	"regexp"
	"strings"
	"time"

	"filo/internal/llm"
)

// Embedder åµŒå…¥æ¥å£
type Embedder interface {
	Embed(text string) []float64
	Similarity(v1, v2 []float64) float64
}

// LocalEmbedder æœ¬åœ°åµŒå…¥ï¼ˆä¸ä¾èµ–å¤–éƒ¨æœåŠ¡ï¼‰
type LocalEmbedder struct {
	dimension int
}

// NewLocalEmbedder åˆ›å»ºæœ¬åœ°åµŒå…¥å™¨
func NewLocalEmbedder() *LocalEmbedder {
	return &LocalEmbedder{dimension: 256}
}

// Embed ç”ŸæˆåµŒå…¥å‘é‡
func (e *LocalEmbedder) Embed(text string) []float64 {
	vec := make([]float64, e.dimension)
	text = strings.ToLower(text)

	// å­—ç¬¦çº§ç‰¹å¾
	for i, char := range text {
		h := fnv.New64a()
		h.Write([]byte(string(char)))
		idx := int(h.Sum64() % uint64(e.dimension))
		vec[idx] += 1.0 / float64(i+1)
	}

	// è¯çº§ç‰¹å¾
	re := regexp.MustCompile(`[\p{Han}]+|[a-zA-Z]+|\d+`)
	words := re.FindAllString(text, -1)
	for i, word := range words {
		h := fnv.New64a()
		h.Write([]byte(word))
		idx := int(h.Sum64() % uint64(e.dimension))
		vec[idx] += 2.0 / float64(i+1)
	}

	// N-gram ç‰¹å¾
	for i := 0; i < len(text)-2; i++ {
		ngram := text[i : i+3]
		h := fnv.New64a()
		h.Write([]byte(ngram))
		idx := int(h.Sum64() % uint64(e.dimension))
		vec[idx] += 0.5
	}

	return normalize(vec)
}

// Similarity è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
func (e *LocalEmbedder) Similarity(v1, v2 []float64) float64 {
	if len(v1) != len(v2) {
		return 0
	}
	var dot, n1, n2 float64
	for i := range v1 {
		dot += v1[i] * v2[i]
		n1 += v1[i] * v1[i]
		n2 += v2[i] * v2[i]
	}
	if n1 == 0 || n2 == 0 {
		return 0
	}
	return dot / (math.Sqrt(n1) * math.Sqrt(n2))
}

func normalize(vec []float64) []float64 {
	var sum float64
	for _, v := range vec {
		sum += v * v
	}
	norm := math.Sqrt(sum)
	if norm == 0 {
		return vec
	}
	result := make([]float64, len(vec))
	for i, v := range vec {
		result[i] = v / norm
	}
	return result
}

// OllamaEmbedder ä½¿ç”¨ Ollama çš„åµŒå…¥å™¨
type OllamaEmbedder struct {
	client   *llm.Client
	fallback *LocalEmbedder
}

// NewOllamaEmbedder åˆ›å»º Ollama åµŒå…¥å™¨
func NewOllamaEmbedder() *OllamaEmbedder {
	return &OllamaEmbedder{
		client:   llm.NewClient(),
		fallback: NewLocalEmbedder(),
	}
}

// Embed ç”ŸæˆåµŒå…¥å‘é‡
func (e *OllamaEmbedder) Embed(text string) []float64 {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	vec, err := e.client.Embed(ctx, text)
	if err != nil {
		return e.fallback.Embed(text)
	}
	return vec
}

// Similarity è®¡ç®—ç›¸ä¼¼åº¦
func (e *OllamaEmbedder) Similarity(v1, v2 []float64) float64 {
	return e.fallback.Similarity(v1, v2)
}

// NewEmbedder åˆ›å»ºåµŒå…¥å™¨ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
func NewEmbedder() Embedder {
	// é»˜è®¤ä½¿ç”¨æœ¬åœ°åµŒå…¥ï¼ˆæ›´å¿«æ›´ç¨³å®šï¼‰
	return NewLocalEmbedder()
}
```

### `internal/scanner/scanner.go`

```go
package scanner

import (
	"os"
	"path/filepath"
	"sort"
	"strings"
	"time"

	"filo/internal/ui"
)

// FileInfo æ–‡ä»¶ä¿¡æ¯
type FileInfo struct {
	Path         string
	Name         string
	Extension    string
	Size         int64
	ModifiedTime time.Time
	IsDir        bool
}

// è·³è¿‡çš„æ–‡ä»¶å’Œç›®å½•
var skipNames = map[string]bool{
	".DS_Store": true, "Thumbs.db": true, "desktop.ini": true,
	"$RECYCLE.BIN": true, ".git": true, ".svn": true,
	"__pycache__": true, "node_modules": true, ".idea": true,
	".vscode": true, ".Trash": true, ".filo": true,
}

// ScanDirectory æ‰«æç›®å½•
func ScanDirectory(dir string, recursive bool) ([]FileInfo, error) {
	var files []FileInfo

	absDir, err := filepath.Abs(dir)
	if err != nil {
		return nil, err
	}

	walkFn := func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		name := info.Name()

		// è·³è¿‡éšè—æ–‡ä»¶
		if strings.HasPrefix(name, ".") {
			if info.IsDir() {
				return filepath.SkipDir
			}
			return nil
		}

		// è·³è¿‡ç‰¹å®šæ–‡ä»¶/ç›®å½•
		if skipNames[name] {
			if info.IsDir() {
				return filepath.SkipDir
			}
			return nil
		}

		// è·³è¿‡å·²æ•´ç†ç›®å½•
		if strings.Contains(path, "å·²æ•´ç†") || strings.Contains(path, "Organized") {
			if info.IsDir() {
				return filepath.SkipDir
			}
			return nil
		}

		// è·³è¿‡æ ¹ç›®å½•
		if path == absDir {
			return nil
		}

		// éé€’å½’æ¨¡å¼åªæ‰«æç¬¬ä¸€å±‚
		if !recursive {
			rel, _ := filepath.Rel(absDir, path)
			if strings.Contains(rel, string(os.PathSeparator)) {
				if info.IsDir() {
					return filepath.SkipDir
				}
				return nil
			}
		}

		files = append(files, FileInfo{
			Path:         path,
			Name:         name,
			Extension:    strings.ToLower(filepath.Ext(name)),
			Size:         info.Size(),
			ModifiedTime: info.ModTime(),
			IsDir:        info.IsDir(),
		})

		return nil
	}

	err = filepath.Walk(absDir, walkFn)
	return files, err
}

// Statistics æ–‡ä»¶ç»Ÿè®¡
type Statistics struct {
	TotalFiles  int
	TotalDirs   int
	TotalSize   int64
	ExtStats    map[string]ExtStat
}

// ExtStat æ‰©å±•åç»Ÿè®¡
type ExtStat struct {
	Count int
	Size  int64
}

// GetStatistics è·å–ç»Ÿè®¡ä¿¡æ¯
func GetStatistics(files []FileInfo) Statistics {
	stats := Statistics{
		ExtStats: make(map[string]ExtStat),
	}

	for _, f := range files {
		if f.IsDir {
			stats.TotalDirs++
			continue
		}

		stats.TotalFiles++
		stats.TotalSize += f.Size

		ext := f.Extension
		if ext == "" {
			ext = "(æ— æ‰©å±•å)"
		}

		es := stats.ExtStats[ext]
		es.Count++
		es.Size += f.Size
		stats.ExtStats[ext] = es
	}

	return stats
}

// PrintStatistics æ‰“å°ç»Ÿè®¡ä¿¡æ¯
func PrintStatistics(files []FileInfo) {
	stats := GetStatistics(files)

	ui.Title("ğŸ“Š", "æ–‡ä»¶ç»Ÿè®¡")
	ui.Divider()

	ui.Info("ğŸ“ æ–‡ä»¶å¤¹: %d ä¸ª", stats.TotalDirs)
	ui.Info("ğŸ“„ æ–‡ä»¶:   %d ä¸ª", stats.TotalFiles)
	ui.Info("ğŸ’¾ æ€»å¤§å°: %s", ui.FormatSize(stats.TotalSize))

	if len(stats.ExtStats) > 0 {
		ui.Info("")
		ui.Info("æŒ‰ç±»å‹ç»Ÿè®¡:")

		// æ’åº
		type kv struct {
			Ext  string
			Stat ExtStat
		}
		var sorted []kv
		for k, v := range stats.ExtStats {
			sorted = append(sorted, kv{k, v})
		}
		sort.Slice(sorted, func(i, j int) bool {
			return sorted[i].Stat.Count > sorted[j].Stat.Count
		})

		for i, kv := range sorted {
			if i >= 12 {
				ui.Dim("  ... è¿˜æœ‰ %d ç§ç±»å‹", len(sorted)-12)
				break
			}
			ui.Info("  %-12s %4d ä¸ª  %10s", kv.Ext, kv.Stat.Count, ui.FormatSize(kv.Stat.Size))
		}
	}
}
```

### `internal/memory/memory.go`

```go
package memory

import (
	"path/filepath"
	"regexp"
	"strings"

	"filo/internal/config"
	"filo/internal/embedding"
	"filo/internal/storage"
)

// Match è®°å¿†åŒ¹é…ç»“æœ
type Match struct {
	Category    string
	Subcategory string
	Confidence  float64
	Source      string // rule, vector, history
	Reasoning   string
}

// Memory è®°å¿†ç³»ç»Ÿ
type Memory struct {
	db       *storage.Database
	embedder embedding.Embedder
	cfg      *config.Config
}

// NewMemory åˆ›å»ºè®°å¿†ç³»ç»Ÿ
func NewMemory() (*Memory, error) {
	db, err := storage.NewDatabase()
	if err != nil {
		return nil, err
	}

	return &Memory{
		db:       db,
		embedder: embedding.NewEmbedder(),
		cfg:      config.Get(),
	}, nil
}

// Close å…³é—­è®°å¿†ç³»ç»Ÿ
func (m *Memory) Close() error {
	return m.db.Close()
}

// Query æŸ¥è¯¢æ–‡ä»¶çš„åˆ†ç±»è®°å¿†
func (m *Memory) Query(filename string) *Match {
	// 1. è§„åˆ™åŒ¹é…ï¼ˆæœ€å¿«ï¼‰
	if match := m.matchRules(filename); match != nil {
		if match.Confidence >= m.cfg.SimilarityThreshold {
			return match
		}
	}

	// 2. å‘é‡åŒ¹é…
	if match := m.matchVectors(filename); match != nil {
		if match.Confidence >= m.cfg.SimilarityThreshold {
			return match
		}
	}

	// 3. å†å²åŒ¹é…
	if match := m.matchHistory(filename); match != nil {
		if match.Confidence >= m.cfg.SimilarityThreshold {
			return match
		}
	}

	return nil
}

func (m *Memory) matchRules(filename string) *Match {
	keywords := extractKeywords(filename)
	ext := strings.ToLower(filepath.Ext(filename))

	rules, err := m.db.GetMatchingRules(filename, keywords, ext)
	if err != nil || len(rules) == 0 {
		return nil
	}

	best := rules[0]

	// ç½®ä¿¡åº¦è®¡ç®—
	conf := 0.6 + float64(best.HitCount)/50.0*0.35
	if conf > 0.95 {
		conf = 0.95
	}

	return &Match{
		Category:    best.Category,
		Subcategory: best.Subcategory,
		Confidence:  conf,
		Source:      "rule",
		Reasoning:   "åŒ¹é…è§„åˆ™: " + best.PatternType + "ã€Œ" + best.Pattern + "ã€",
	}
}

func (m *Memory) matchVectors(filename string) *Match {
	queryVec := m.embedder.Embed(filename)
	vectors, err := m.db.SearchVectors(200)
	if err != nil || len(vectors) == 0 {
		return nil
	}

	var best struct {
		Filename    string
		Category    string
		Subcategory string
		Similarity  float64
	}

	for _, v := range vectors {
		sim := m.embedder.Similarity(queryVec, v.Vector)
		if sim > best.Similarity {
			best.Filename = v.Filename
			best.Category = v.Category
			best.Subcategory = v.Subcategory
			best.Similarity = sim
		}
	}

	if best.Similarity < m.cfg.SimilarityThreshold {
		return nil
	}

	return &Match{
		Category:    best.Category,
		Subcategory: best.Subcategory,
		Confidence:  best.Similarity,
		Source:      "vector",
		Reasoning:   "ç›¸ä¼¼æ–‡ä»¶: " + best.Filename,
	}
}

func (m *Memory) matchHistory(filename string) *Match {
	keywords := extractKeywords(filename)
	if len(keywords) == 0 {
		return nil
	}

	records, err := m.db.GetSimilarClassifications(keywords, 5)
	if err != nil || len(records) == 0 {
		return nil
	}

	best := records[0]
	sim := filenameSimilarity(filename, best.Filename)

	return &Match{
		Category:    best.Category,
		Subcategory: best.Subcategory,
		Confidence:  sim * 0.9,
		Source:      "history",
		Reasoning:   "å†å²è®°å½•: " + best.Filename,
	}
}

// Learn ä»åˆ†ç±»ç»“æœå­¦ä¹ 
func (m *Memory) Learn(filename, category, subcategory, source string, confidence float64, userConfirmed bool) error {
	ext := strings.ToLower(filepath.Ext(filename))
	keywords := extractKeywords(filename)

	// æ·»åŠ å†å²è®°å½•
	m.db.AddClassification(filename, ext, category, subcategory, source, confidence, keywords, userConfirmed)

	// æ·»åŠ å‘é‡
	vec := m.embedder.Embed(filename)
	m.db.SaveVector(filename, category, subcategory, vec)

	// ç”¨æˆ·ç¡®è®¤æ—¶å­¦ä¹ è§„åˆ™
	if userConfirmed {
		m.learnRules(filename, category, subcategory)
	}

	return nil
}

func (m *Memory) learnRules(filename, category, subcategory string) {
	ext := strings.ToLower(filepath.Ext(filename))
	keywords := extractKeywords(filename)

	// æ‰©å±•åè§„åˆ™
	if ext != "" {
		m.db.AddOrUpdateRule(ext, "extension", category, subcategory, 5)
	}

	// å…³é”®è¯è§„åˆ™
	for _, kw := range keywords {
		if len(kw) >= 2 {
			m.db.AddOrUpdateRule(strings.ToLower(kw), "keyword", category, subcategory, 10)
		}
	}
}

// LearnFromCorrection ä»ç”¨æˆ·çº æ­£å­¦ä¹ 
func (m *Memory) LearnFromCorrection(filename, origCat, corrCat, origSub, corrSub string) error {
	// è®°å½•åé¦ˆ
	m.db.AddFeedback(filename, origCat, corrCat, origSub, corrSub)

	// é«˜ä¼˜å…ˆçº§å­¦ä¹ 
	keywords := extractKeywords(filename)
	for _, kw := range keywords {
		if len(kw) >= 2 {
			m.db.AddOrUpdateRule(strings.ToLower(kw), "keyword", corrCat, corrSub, 20)
		}
	}

	return nil
}

// GetLearnedRules è·å–å·²å­¦ä¹ çš„è§„åˆ™
func (m *Memory) GetLearnedRules(limit int) []map[string]string {
	rules, err := m.db.GetTopRules(limit)
	if err != nil {
		return nil
	}

	result := make([]map[string]string, 0, len(rules))
	for _, r := range rules {
		result = append(result, map[string]string{
			"pattern":     r["pattern"].(string),
			"category":    r["category"].(string),
			"subcategory": r["subcategory"].(string),
		})
	}
	return result
}

// GetStatistics è·å–ç»Ÿè®¡
func (m *Memory) GetStatistics() (map[string]interface{}, error) {
	stats, err := m.db.GetStatistics()
	if err != nil {
		return nil, err
	}
	stats["learning_enabled"] = m.cfg.EnableLearning
	return stats, nil
}

// è¾…åŠ©å‡½æ•°

func extractKeywords(filename string) []string {
	name := strings.TrimSuffix(filename, filepath.Ext(filename))
	re := regexp.MustCompile(`[\p{Han}]+|[a-zA-Z]{2,}|\d{4,}`)
	return re.FindAllString(name, -1)
}

func filenameSimilarity(n1, n2 string) float64 {
	w1 := make(map[string]bool)
	w2 := make(map[string]bool)

	re := regexp.MustCompile(`[\p{Han}]+|[a-zA-Z]+|\d+`)
	for _, w := range re.FindAllString(strings.ToLower(n1), -1) {
		w1[w] = true
	}
	for _, w := range re.FindAllString(strings.ToLower(n2), -1) {
		w2[w] = true
	}

	if len(w1) == 0 || len(w2) == 0 {
		return 0
	}

	var intersection int
	for w := range w1 {
		if w2[w] {
			intersection++
		}
	}

	union := len(w1) + len(w2) - intersection
	return float64(intersection) / float64(union)
}
```

### `internal/classifier/classifier.go`

```go
package classifier

import (
	"context"
	"fmt"
	"time"

	"github.com/schollz/progressbar/v3"

	"filo/internal/config"
	"filo/internal/llm"
	"filo/internal/memory"
	"filo/internal/scanner"
	"filo/internal/ui"
)

// Result åˆ†ç±»ç»“æœ
type Result struct {
	FileInfo    scanner.FileInfo
	Category    string
	Subcategory string
	Confidence  float64
	Reasoning   string
	Source      string // memory, llm
	Keywords    []string
}

// Classifier åˆ†ç±»å™¨
type Classifier struct {
	memory *memory.Memory
	llm    *llm.Client
	cfg    *config.Config
}

// NewClassifier åˆ›å»ºåˆ†ç±»å™¨
func NewClassifier() (*Classifier, error) {
	mem, err := memory.NewMemory()
	if err != nil {
		return nil, err
	}

	return &Classifier{
		memory: mem,
		llm:    llm.NewClient(),
		cfg:    config.Get(),
	}, nil
}

// Close å…³é—­åˆ†ç±»å™¨
func (c *Classifier) Close() error {
	return c.memory.Close()
}

// Classify åˆ†ç±»æ–‡ä»¶
func (c *Classifier) Classify(files []scanner.FileInfo, verbose bool) ([]Result, error) {
	var memoryResults []Result
	var llmNeeded []scanner.FileInfo

	ui.Title("ğŸ§ ", "æ£€æŸ¥å­¦ä¹ è®°å¿†")

	// å…ˆä»è®°å¿†è·å–
	for _, f := range files {
		if f.IsDir {
			continue
		}

		match := c.memory.Query(f.Name)
		if match != nil && match.Confidence >= c.cfg.SimilarityThreshold {
			memoryResults = append(memoryResults, Result{
				FileInfo:    f,
				Category:    match.Category,
				Subcategory: match.Subcategory,
				Confidence:  match.Confidence,
				Reasoning:   match.Reasoning,
				Source:      "memory",
			})

			if verbose {
				ui.Success("%s â†’ %s (%s)", f.Name, match.Category, match.Source)
			}
		} else {
			llmNeeded = append(llmNeeded, f)
		}
	}

	if len(memoryResults) > 0 {
		ui.Success("ä»è®°å¿†è·å– %d ä¸ªåˆ†ç±»", len(memoryResults))
	}

	// LLM åˆ†ç±»å‰©ä½™æ–‡ä»¶
	var llmResults []Result
	if len(llmNeeded) > 0 {
		ui.Title("ğŸ¤–", fmt.Sprintf("AIåˆ†ç±» %d ä¸ªæ–‡ä»¶", len(llmNeeded)))

		rules := c.memory.GetLearnedRules(30)
		var err error
		llmResults, err = c.classifyWithLLM(llmNeeded, rules, verbose)
		if err != nil {
			ui.Warning("éƒ¨åˆ†æ–‡ä»¶åˆ†ç±»å¤±è´¥: %v", err)
		}

		// å­¦ä¹ ç»“æœ
		if c.cfg.EnableLearning {
			for _, r := range llmResults {
				c.memory.Learn(r.FileInfo.Name, r.Category, r.Subcategory, "llm", r.Confidence, false)
			}
		}
	}

	// åˆå¹¶ç»“æœ
	results := append(memoryResults, llmResults...)

	// æŒ‰åŸé¡ºåºæ’åº
	order := make(map[string]int)
	for i, f := range files {
		order[f.Path] = i
	}
	for i := 0; i < len(results); i++ {
		for j := i + 1; j < len(results); j++ {
			if order[results[i].FileInfo.Path] > order[results[j].FileInfo.Path] {
				results[i], results[j] = results[j], results[i]
			}
		}
	}

	return results, nil
}

func (c *Classifier) classifyWithLLM(files []scanner.FileInfo, rules []map[string]string, verbose bool) ([]Result, error) {
	var results []Result
	batchSize := c.cfg.BatchSize

	bar := progressbar.NewOptions(len(files),
		progressbar.OptionSetDescription("  åˆ†ç±»ä¸­"),
		progressbar.OptionSetTheme(progressbar.Theme{
			Saucer:        "â–ˆ",
			SaucerHead:    "â–ˆ",
			SaucerPadding: "â–‘",
			BarStart:      "[",
			BarEnd:        "]",
		}),
		progressbar.OptionShowCount(),
	)

	for i := 0; i < len(files); i += batchSize {
		end := i + batchSize
		if end > len(files) {
			end = len(files)
		}

		batch := files[i:end]
		batchData := make([]map[string]interface{}, len(batch))
		for j, f := range batch {
			batchData[j] = map[string]interface{}{
				"name":      f.Name,
				"extension": f.Extension,
				"size":      f.Size,
			}
		}

		ctx, cancel := context.WithTimeout(context.Background(), 120*time.Second)
		resp, err := c.llm.ClassifyFiles(ctx, batchData, rules)
		cancel()

		if err != nil {
			// å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤åˆ†ç±»
			for _, f := range batch {
				results = append(results, Result{
					FileInfo:    f,
					Category:    "æœªåˆ†ç±»",
					Subcategory: "å…¶ä»–",
					Confidence:  0,
					Reasoning:   fmt.Sprintf("åˆ†ç±»å¤±è´¥: %v", err),
					Source:      "error",
				})
			}
		} else {
			classifications, _ := resp["classifications"].([]interface{})
			for j, cls := range classifications {
				if j >= len(batch) {
					break
				}
				clsMap, _ := cls.(map[string]interface{})
				if clsMap == nil {
					continue
				}

				results = append(results, Result{
					FileInfo:    batch[j],
					Category:    getString(clsMap, "category", "æœªåˆ†ç±»"),
					Subcategory: getString(clsMap, "subcategory", "å…¶ä»–"),
					Confidence:  getFloat(clsMap, "confidence", 0.5),
					Reasoning:   getString(clsMap, "reasoning", ""),
					Source:      "llm",
					Keywords:    getStringSlice(clsMap, "keywords"),
				})
			}
		}

		bar.Add(len(batch))
	}

	fmt.Println()
	return results, nil
}

// Confirm ç¡®è®¤åˆ†ç±»
func (c *Classifier) Confirm(r Result) {
	c.memory.Learn(r.FileInfo.Name, r.Category, r.Subcategory, r.Source, r.Confidence, true)
}

// Correct çº æ­£åˆ†ç±»
func (c *Classifier) Correct(r Result, newCat, newSub string) {
	c.memory.LearnFromCorrection(r.FileInfo.Name, r.Category, newCat, r.Subcategory, newSub)
}

// GetStatistics è·å–ç»Ÿè®¡
func (c *Classifier) GetStatistics() (map[string]interface{}, error) {
	return c.memory.GetStatistics()
}

// è¾…åŠ©å‡½æ•°
func getString(m map[string]interface{}, key, def string) string {
	if v, ok := m[key].(string); ok {
		return v
	}
	return def
}

func getFloat(m map[string]interface{}, key string, def float64) float64 {
	if v, ok := m[key].(float64); ok {
		return v
	}
	return def
}

func getStringSlice(m map[string]interface{}, key string) []string {
	if v, ok := m[key].([]interface{}); ok {
		result := make([]string, 0, len(v))
		for _, item := range v {
			if s, ok := item.(string); ok {
				result = append(result, s)
			}
		}
		return result
	}
	return nil
}
```

### `internal/organizer/organizer.go`

```go
package organizer

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"time"

	"filo/internal/classifier"
	"filo/internal/ui"
)

// Plan æ•´ç†è®¡åˆ’
type Plan struct {
	TargetDir string
	Actions   map[string][]classifier.Result
}

// TotalFiles æ€»æ–‡ä»¶æ•°
func (p *Plan) TotalFiles() int {
	total := 0
	for _, files := range p.Actions {
		total += len(files)
	}
	return total
}

// TotalFolders æ€»åˆ†ç±»æ•°
func (p *Plan) TotalFolders() int {
	return len(p.Actions)
}

// GeneratePlan ç”Ÿæˆæ•´ç†è®¡åˆ’
func GeneratePlan(results []classifier.Result, targetDir string) *Plan {
	plan := &Plan{
		TargetDir: targetDir,
		Actions:   make(map[string][]classifier.Result),
	}

	for _, r := range results {
		var folder string
		if r.Subcategory != "" && r.Subcategory != "å…¶ä»–" && r.Subcategory != "æœªçŸ¥" {
			folder = filepath.Join(r.Category, r.Subcategory)
		} else {
			folder = r.Category
		}

		plan.Actions[folder] = append(plan.Actions[folder], r)
	}

	return plan
}

// PrintPlan æ‰“å°è®¡åˆ’
func PrintPlan(plan *Plan) {
	lines := []string{
		fmt.Sprintf("ğŸ“‚ ç›®æ ‡: %s", plan.TargetDir),
		fmt.Sprintf("ğŸ“„ æ–‡ä»¶: %d ä¸ª", plan.TotalFiles()),
		fmt.Sprintf("ğŸ“ åˆ†ç±»: %d ç§", plan.TotalFolders()),
	}
	ui.Box("ğŸ“‹ æ•´ç†è®¡åˆ’", lines)

	// æ’åºæ–‡ä»¶å¤¹
	folders := make([]string, 0, len(plan.Actions))
	for f := range plan.Actions {
		folders = append(folders, f)
	}
	sort.Strings(folders)

	for _, folder := range folders {
		files := plan.Actions[folder]
		fmt.Printf("\n  %s %s/ %s\n", ui.Green("ğŸ“"), ui.Bold(folder), ui.Gray(fmt.Sprintf("(%dä¸ª)", len(files))))

		for i, r := range files {
			if i >= 5 {
				ui.Dim("      ... è¿˜æœ‰ %d ä¸ªæ–‡ä»¶", len(files)-5)
				break
			}

			icon := ui.ConfidenceIcon(r.Confidence)
			source := ui.SourceIcon(r.Source)
			fmt.Printf("      %s %s %s\n", icon, source, r.FileInfo.Name)

			if r.Reasoning != "" {
				reason := r.Reasoning
				if len(reason) > 45 {
					reason = reason[:45] + "..."
				}
				ui.Dim("         â””â”€ %s", reason)
			}
		}
	}
	fmt.Println()
}

// InteractiveReview äº¤äº’å¼å®¡æŸ¥
func InteractiveReview(plan *Plan, clf *classifier.Classifier) *Plan {
	ui.Warning("äº¤äº’å®¡æŸ¥ (y:ç¡®è®¤ n:è·³è¿‡ c:ä¿®æ”¹ q:ç»“æŸ)")

	reader := bufio.NewReader(os.Stdin)
	modified := false

	for folder, files := range plan.Actions {
		for i, r := range files {
			if r.Confidence < 0.7 {
				fmt.Println()
				ui.Warning("ä½ç½®ä¿¡åº¦: %s", r.FileInfo.Name)
				ui.Info("   åˆ†ç±»: %s/%s", r.Category, r.Subcategory)
				ui.Info("   ç½®ä¿¡åº¦: %.0f%%", r.Confidence*100)
				ui.Dim("   ç†ç”±: %s", r.Reasoning)

				fmt.Print("  æ“ä½œ [y/n/c/q]: ")
				input, _ := reader.ReadString('\n')
				input = strings.TrimSpace(strings.ToLower(input))

				switch input {
				case "q":
					goto done
				case "y":
					clf.Confirm(r)
				case "c":
					fmt.Print("  æ–°ä¸»åˆ†ç±»: ")
					newCat, _ := reader.ReadString('\n')
					newCat = strings.TrimSpace(newCat)
					if newCat == "" {
						newCat = r.Category
					}

					fmt.Print("  æ–°å­åˆ†ç±»: ")
					newSub, _ := reader.ReadString('\n')
					newSub = strings.TrimSpace(newSub)
					if newSub == "" {
						newSub = r.Subcategory
					}

					clf.Correct(r, newCat, newSub)
					plan.Actions[folder][i].Category = newCat
					plan.Actions[folder][i].Subcategory = newSub
					modified = true
				}
			}
		}
	}

done:
	if modified {
		var all []classifier.Result
		for _, files := range plan.Actions {
			all = append(all, files...)
		}
		return GeneratePlan(all, plan.TargetDir)
	}
	return plan
}

// ExecuteResult æ‰§è¡Œç»“æœ
type ExecuteResult struct {
	Success int
	Errors  int
}

// Execute æ‰§è¡Œè®¡åˆ’
func Execute(plan *Plan, clf *classifier.Classifier, verbose bool) ExecuteResult {
	ui.Title("ğŸš€", "æ‰§è¡Œæ•´ç†")

	result := ExecuteResult{}

	for folder, files := range plan.Actions {
		targetFolder := filepath.Join(plan.TargetDir, folder)
		os.MkdirAll(targetFolder, 0755)

		for _, r := range files {
			src := r.FileInfo.Path
			dst := filepath.Join(targetFolder, r.FileInfo.Name)

			// å¤„ç†é‡å
			dst = handleDuplicate(dst)

			if verbose {
				ui.Info("ç§»åŠ¨: %s", r.FileInfo.Name)
				ui.Dim("  â†’ %s", dst)
			}

			if err := os.Rename(src, dst); err != nil {
				result.Errors++
				if verbose {
					ui.Error("å¤±è´¥: %v", err)
				}
			} else {
				result.Success++
				clf.Confirm(r)
			}
		}
	}

	// ä¿å­˜æ—¥å¿—
	logPath := filepath.Join(plan.TargetDir, fmt.Sprintf("filo_log_%s.json", time.Now().Format("20060102_150405")))
	logData := map[string]interface{}{
		"timestamp": time.Now().Format(time.RFC3339),
		"success":   result.Success,
		"errors":    result.Errors,
	}
	if data, err := json.MarshalIndent(logData, "", "  "); err == nil {
		os.WriteFile(logPath, data, 0644)
	}

	fmt.Println()
	ui.Success("æˆåŠŸ: %d ä¸ªæ–‡ä»¶", result.Success)
	if result.Errors > 0 {
		ui.Error("å¤±è´¥: %d ä¸ªæ–‡ä»¶", result.Errors)
	}
	ui.Dim("æ—¥å¿—: %s", logPath)

	return result
}

func handleDuplicate(path string) string {
	if _, err := os.Stat(path); os.IsNotExist(err) {
		return path
	}

	dir := filepath.Dir(path)
	ext := filepath.Ext(path)
	name := strings.TrimSuffix(filepath.Base(path), ext)

	for i := 1; ; i++ {
		newPath := filepath.Join(dir, fmt.Sprintf("%s_%d%s", name, i, ext))
		if _, err := os.Stat(newPath); os.IsNotExist(err) {
			return newPath
		}
	}
}

// Confirm ç¡®è®¤æç¤º
func Confirm(prompt string) bool {
	fmt.Printf("%s [y/N]: ", prompt)
	reader := bufio.NewReader(os.Stdin)
	input, _ := reader.ReadString('\n')
	input = strings.TrimSpace(strings.ToLower(input))
	return input == "y" || input == "yes"
}
```

### `cmd/root.go`

```go
package cmd

import (
	"fmt"
	"os"
	"path/filepath"

	"github.com/spf13/cobra"

	"filo/internal/classifier"
	"filo/internal/config"
	"filo/internal/llm"
	"filo/internal/organizer"
	"filo/internal/scanner"
	"filo/internal/ui"
)

var (
	targetDir   string
	model       string
	dryRun      bool
	verbose     bool
	interactive bool
	noLearning  bool
)

var rootCmd = &cobra.Command{
	Use:   "filo [ç›®å½•]",
	Short: "filo - æ–‡ä»¶æ™ºç†ï¼Œè¶Šç”¨è¶Šæ‡‚ä½ ",
	Long: `
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
  â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
  â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• 
  
  æ–‡ä»¶æ™ºç† Â· è¶Šç”¨è¶Šæ‡‚ä½   v` + config.Version + `

  ğŸ§  æœ¬åœ°AIï¼Œéšç§å®‰å…¨
  ğŸ“š è‡ªåŠ¨å­¦ä¹ ä½ çš„æ•´ç†ä¹ æƒ¯
  ğŸš€ è¶Šç”¨è¶Šå¿«ï¼Œè¶Šç”¨è¶Šå‡†

ç¤ºä¾‹:
  filo ~/Downloads              # æ•´ç†ä¸‹è½½æ–‡ä»¶å¤¹
  filo ~/Downloads -n           # é¢„è§ˆæ¨¡å¼
  filo ~/Downloads -i           # äº¤äº’å¼å®¡æŸ¥
  filo setup                    # å®‰è£…å‘å¯¼
  filo stats                    # æŸ¥çœ‹å­¦ä¹ ç»Ÿè®¡
`,
	Args: cobra.MaximumNArgs(1),
	Run:  runOrganize,
}

func init() {
	rootCmd.Flags().StringVarP(&targetDir, "target", "t", "", "ç›®æ ‡ç›®å½•")
	rootCmd.Flags().StringVarP(&model, "model", "m", "", "ä½¿ç”¨çš„æ¨¡å‹")
	rootCmd.Flags().BoolVarP(&dryRun, "dry-run", "n", false, "é¢„è§ˆæ¨¡å¼")
	rootCmd.Flags().BoolVarP(&verbose, "verbose", "v", false, "è¯¦ç»†è¾“å‡º")
	rootCmd.Flags().BoolVarP(&interactive, "interactive", "i", false, "äº¤äº’å¼å®¡æŸ¥")
	rootCmd.Flags().BoolVar(&noLearning, "no-learning", false, "ç¦ç”¨å­¦ä¹ ")
}

func Execute() {
	if err := rootCmd.Execute(); err != nil {
		fmt.Println(err)
		os.Exit(1)
	}
}

func runOrganize(cmd *cobra.Command, args []string) {
	if len(args) == 0 {
		cmd.Help()
		return
	}

	sourceDir := args[0]

	ui.Banner()

	// æ›´æ–°é…ç½®
	cfg := config.Get()
	if model != "" {
		cfg.SetModel(model)
	}
	if noLearning {
		cfg.EnableLearning = false
	}

	if targetDir == "" {
		targetDir = filepath.Join(sourceDir, "å·²æ•´ç†")
	}

	// æ£€æŸ¥æºç›®å½•
	if _, err := os.Stat(sourceDir); os.IsNotExist(err) {
		ui.Error("ç›®å½•ä¸å­˜åœ¨: %s", sourceDir)
		return
	}

	// æ£€æŸ¥ Ollama
	client := llm.NewClient()
	if !client.IsAvailable() {
		ui.Error("Ollama æœåŠ¡æœªè¿è¡Œ")
		ui.Info("è¯·å…ˆå¯åŠ¨: ollama serve")
		ui.Info("æˆ–è¿è¡Œ: filo setup")
		return
	}

	if !client.HasModel(cfg.LLMModel) {
		ui.Error("æ¨¡å‹ %s æœªå®‰è£…", cfg.LLMModel)
		ui.Info("è¿è¡Œ 'filo setup' å®‰è£…æ¨¡å‹")
		return
	}

	// 1. æ‰«æ
	ui.Title("ğŸ“‚", fmt.Sprintf("æ‰«æ: %s", sourceDir))
	files, err := scanner.ScanDirectory(sourceDir, false)
	if err != nil {
		ui.Error("æ‰«æå¤±è´¥: %v", err)
		return
	}

	fileCount := 0
	for _, f := range files {
		if !f.IsDir {
			fileCount++
		}
	}
	ui.Success("æ‰¾åˆ° %d ä¸ªæ–‡ä»¶", fileCount)

	if fileCount == 0 {
		ui.Warning("æ²¡æœ‰æ–‡ä»¶éœ€è¦æ•´ç†")
		return
	}

	// 2. åˆ†ç±»
	clf, err := classifier.NewClassifier()
	if err != nil {
		ui.Error("åˆå§‹åŒ–åˆ†ç±»å™¨å¤±è´¥: %v", err)
		return
	}
	defer clf.Close()

	results, err := clf.Classify(files, verbose)
	if err != nil {
		ui.Error("åˆ†ç±»å¤±è´¥: %v", err)
		return
	}

	// 3. ç”Ÿæˆè®¡åˆ’
	plan := organizer.GeneratePlan(results, targetDir)
	organizer.PrintPlan(plan)

	// 4. äº¤äº’å®¡æŸ¥
	if interactive {
		plan = organizer.InteractiveReview(plan, clf)
		organizer.PrintPlan(plan)
	}

	// 5. æ‰§è¡Œ
	if dryRun {
		ui.Warning("é¢„è§ˆæ¨¡å¼ - æœªæ‰§è¡Œå®é™…æ“ä½œ")
		ui.Dim("å»æ‰ -n å‚æ•°æ‰§è¡Œå®é™…æ•´ç†")
	} else {
		if organizer.Confirm("\nç¡®è®¤æ‰§è¡Œæ•´ç†?") {
			organizer.Execute(plan, clf, verbose)
		} else {
			ui.Warning("å·²å–æ¶ˆ")
		}
	}
}
```

### `cmd/setup.go`

```go
package cmd

import (
	"bufio"
	"fmt"
	"os"
	"os/exec"
	"runtime"
	"strings"
	"time"

	"github.com/spf13/cobra"

	"filo/internal/config"
	"filo/internal/llm"
	"filo/internal/ui"
)

var setupCmd = &cobra.Command{
	Use:   "setup",
	Short: "å®‰è£…å‘å¯¼",
	Long:  "å®‰è£…å’Œé…ç½® Ollama åŠæ¨èæ¨¡å‹",
	Run:   runSetup,
}

func init() {
	rootCmd.AddCommand(setupCmd)
}

func runSetup(cmd *cobra.Command, args []string) {
	ui.Banner()
	ui.Title("ğŸš€", "å®‰è£…å‘å¯¼")
	ui.Divider()

	// 1. æ£€æŸ¥ Ollama
	fmt.Println()
	ui.Info("æ£€æŸ¥ Ollama...")
	ollamaPath, err := exec.LookPath("ollama")
	if err != nil {
		ui.Error("Ollama æœªå®‰è£…")
		printInstallInstructions()
		return
	}
	ui.Success("Ollama å·²å®‰è£…: %s", ollamaPath)

	// 2. å¯åŠ¨æœåŠ¡
	ui.Info("å¯åŠ¨ Ollama æœåŠ¡...")
	startOllama()
	time.Sleep(2 * time.Second)

	client := llm.NewClient()
	for i := 0; i < 5; i++ {
		if client.IsAvailable() {
			break
		}
		time.Sleep(time.Second)
	}

	if !client.IsAvailable() {
		ui.Error("æ— æ³•è¿æ¥ Ollama æœåŠ¡")
		ui.Info("è¯·æ‰‹åŠ¨è¿è¡Œ: ollama serve")
		return
	}
	ui.Success("Ollama æœåŠ¡å·²å¯åŠ¨")

	// 3. æ£€æŸ¥æ¨¡å‹
	fmt.Println()
	ui.Info("å·²å®‰è£…çš„æ¨¡å‹:")
	models, _ := client.ListModels()
	if len(models) == 0 {
		ui.Dim("  (æ— )")
	} else {
		for _, m := range models {
			ui.Info("  - %s", m)
		}
	}

	// 4. ä¸‹è½½æ¨èæ¨¡å‹
	cfg := config.Get()
	recommended := cfg.LLMModel

	hasModel := false
	for _, m := range models {
		if strings.HasPrefix(m, strings.Split(recommended, ":")[0]) {
			hasModel = true
			break
		}
	}

	if !hasModel {
		fmt.Println()
		ui.Warning("æ¨èæ¨¡å‹ %s æœªå®‰è£…", recommended)
		if confirm("æ˜¯å¦ä¸‹è½½?") {
			downloadModel(recommended)
		}
	} else {
		ui.Success("æ¨èæ¨¡å‹å·²å®‰è£…")
	}

	// 5. å®Œæˆ
	fmt.Println()
	ui.Divider()
	ui.Success("è®¾ç½®å®Œæˆï¼")
	fmt.Println()
	ui.Info("ç°åœ¨å¯ä»¥ä½¿ç”¨:")
	fmt.Println()
	fmt.Println("  " + ui.Cyan("filo ~/Downloads -n") + "    # é¢„è§ˆæ•´ç†æ•ˆæœ")
	fmt.Println("  " + ui.Cyan("filo ~/Downloads") + "       # æ‰§è¡Œæ•´ç†")
	fmt.Println()
}

func printInstallInstructions() {
	fmt.Println()
	ui.Info("å®‰è£…æ–¹æ³•:")
	switch runtime.GOOS {
	case "darwin":
		fmt.Println("  brew install ollama")
		fmt.Println("  æˆ–è®¿é—®: https://ollama.com/download/mac")
	case "linux":
		fmt.Println("  curl -fsSL https://ollama.com/install.sh | sh")
	case "windows":
		fmt.Println("  è®¿é—®: https://ollama.com/download/windows")
	default:
		fmt.Println("  è®¿é—®: https://ollama.com/download")
	}
}

func startOllama() {
	cmd := exec.Command("ollama", "serve")
	cmd.Stdout = nil
	cmd.Stderr = nil
	cmd.Start()
}

func downloadModel(model string) {
	ui.Info("ä¸‹è½½ %s ...", model)
	cmd := exec.Command("ollama", "pull", model)
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr
	if err := cmd.Run(); err != nil {
		ui.Error("ä¸‹è½½å¤±è´¥: %v", err)
	} else {
		ui.Success("ä¸‹è½½å®Œæˆ")
	}
}

func confirm(prompt string) bool {
	fmt.Printf("%s [Y/n]: ", prompt)
	reader := bufio.NewReader(os.Stdin)
	input, _ := reader.ReadString('\n')
	input = strings.TrimSpace(strings.ToLower(input))
	return input == "" || input == "y" || input == "yes"
}
```

### `cmd/stats.go`

```go
package cmd

import (
	"fmt"

	"github.com/spf13/cobra"

	"filo/internal/classifier"
	"filo/internal/config"
	"filo/internal/ui"
)

var statsCmd = &cobra.Command{
	Use:   "stats",
	Short: "å­¦ä¹ ç»Ÿè®¡",
	Long:  "æ˜¾ç¤ºå­¦ä¹ è®°å½•å’Œç»Ÿè®¡ä¿¡æ¯",
	Run:   runStats,
}

func init() {
	rootCmd.AddCommand(statsCmd)
}

func runStats(cmd *cobra.Command, args []string) {
	ui.Banner()
	ui.Title("ğŸ“Š", "å­¦ä¹ ç»Ÿè®¡")
	ui.Divider()

	clf, err := classifier.NewClassifier()
	if err != nil {
		ui.Error("åˆå§‹åŒ–å¤±è´¥: %v", err)
		return
	}
	defer clf.Close()

	stats, err := clf.GetStatistics()
	if err != nil {
		ui.Error("è·å–ç»Ÿè®¡å¤±è´¥: %v", err)
		return
	}

	cfg := config.Get()

	fmt.Println()
	ui.Info("ç³»ç»ŸçŠ¶æ€:")
	ui.Info("  å†å²åˆ†ç±»:  %v æ¡", stats["total_records"])
	ui.Info("  ç”¨æˆ·ç¡®è®¤:  %v æ¡", stats["confirmed_records"])
	ui.Info("  å­¦ä¹ è§„åˆ™:  %v æ¡", stats["learned_rules"])
	ui.Info("  å‘é‡è®°å½•:  %v æ¡", stats["vector_count"])
	ui.Info("  ç”¨æˆ·åé¦ˆ:  %v æ¡", stats["feedback_count"])

	learning := "å¼€å¯"
	if !cfg.EnableLearning {
		learning = "å…³é—­"
	}
	ui.Info("  å­¦ä¹ åŠŸèƒ½:  %s", learning)
	ui.Info("  å½“å‰æ¨¡å‹:  %s", cfg.LLMModel)

	// åˆ†ç±»åˆ†å¸ƒ
	if dist, ok := stats["category_distribution"].(map[string]int); ok && len(dist) > 0 {
		fmt.Println()
		ui.Info("åˆ†ç±»åˆ†å¸ƒ:")
		for cat, cnt := range dist {
			ui.Info("  %-12s %d", cat, cnt)
		}
	}
}
```

### `cmd/scan.go`

```go
package cmd

import (
	"github.com/spf13/cobra"

	"filo/internal/scanner"
	"filo/internal/ui"
)

var scanCmd = &cobra.Command{
	Use:   "scan [ç›®å½•]",
	Short: "æ‰«æç»Ÿè®¡",
	Long:  "æ‰«æç›®å½•å¹¶æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯",
	Args:  cobra.ExactArgs(1),
	Run:   runScan,
}

func init() {
	rootCmd.AddCommand(scanCmd)
}

func runScan(cmd *cobra.Command, args []string) {
	ui.Banner()

	dir := args[0]
	files, err := scanner.ScanDirectory(dir, false)
	if err != nil {
		ui.Error("æ‰«æå¤±è´¥: %v", err)
		return
	}

	scanner.PrintStatistics(files)
}
```

### `cmd/models.go`

```go
package cmd

import (
	"fmt"

	"github.com/spf13/cobra"

	"filo/internal/config"
	"filo/internal/llm"
	"filo/internal/ui"
)

var modelsCmd = &cobra.Command{
	Use:   "models",
	Short: "æ¨¡å‹ç®¡ç†",
	Long:  "åˆ—å‡ºå¯ç”¨çš„æœ¬åœ°æ¨¡å‹",
	Run:   runModels,
}

func init() {
	rootCmd.AddCommand(modelsCmd)
}

func runModels(cmd *cobra.Command, args []string) {
	ui.Banner()
	ui.Title("ğŸ¤–", "å¯ç”¨æ¨¡å‹")
	ui.Divider()

	client := llm.NewClient()
	if !client.IsAvailable() {
		ui.Error("Ollama æœåŠ¡æœªè¿è¡Œ")
		ui.Info("è¯·è¿è¡Œ: ollama serve")
		return
	}

	models, err := client.ListModels()
	if err != nil {
		ui.Error("è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: %v", err)
		return
	}

	cfg := config.Get()

	if len(models) == 0 {
		ui.Warning("æœªæ‰¾åˆ°å·²å®‰è£…çš„æ¨¡å‹")
		ui.Info("è¿è¡Œ 'filo setup' å®‰è£…æ¨¡å‹")
		return
	}

	fmt.Println()
	for _, m := range models {
		if m == cfg.LLMModel {
			fmt.Printf("  %s %s %s\n", ui.Green("âœ“"), m, ui.Gray("(å½“å‰)"))
		} else {
			fmt.Printf("    %s\n", m)
		}
	}

	fmt.Println()
	ui.Info("åˆ‡æ¢æ¨¡å‹: filo -m <æ¨¡å‹å> <ç›®å½•>")
}
```

### `cmd/reset.go`

```go
package cmd

import (
	"bufio"
	"fmt"
	"os"
	"strings"

	"github.com/spf13/cobra"

	"filo/internal/storage"
	"filo/internal/ui"
)

var (
	resetRules   bool
	resetHistory bool
	resetAll     bool
)

var resetCmd = &cobra.Command{
	Use:   "reset",
	Short: "é‡ç½®æ•°æ®",
	Long:  "é‡ç½®å­¦ä¹ æ•°æ®å’Œè®°å¿†",
	Run:   runReset,
}

func init() {
	resetCmd.Flags().BoolVar(&resetRules, "rules", false, "é‡ç½®å­¦ä¹ è§„åˆ™")
	resetCmd.Flags().BoolVar(&resetHistory, "history", false, "é‡ç½®å†å²è®°å½•")
	resetCmd.Flags().BoolVar(&resetAll, "all", false, "é‡ç½®æ‰€æœ‰æ•°æ®")
	rootCmd.AddCommand(resetCmd)
}

func runReset(cmd *cobra.Command, args []string) {
	ui.Banner()

	db, err := storage.NewDatabase()
	if err != nil {
		ui.Error("æ•°æ®åº“è¿æ¥å¤±è´¥: %v", err)
		return
	}
	defer db.Close()

	if resetAll {
		if !confirmReset("ç¡®è®¤é‡ç½®æ‰€æœ‰æ•°æ®?") {
			return
		}
		if err := db.ResetAll(); err != nil {
			ui.Error("é‡ç½®å¤±è´¥: %v", err)
			return
		}
		ui.Success("å·²é‡ç½®æ‰€æœ‰æ•°æ®")
		return
	}

	if resetRules {
		if !confirmReset("ç¡®è®¤é‡ç½®å­¦ä¹ è§„åˆ™?") {
			return
		}
		if err := db.ResetRules(); err != nil {
			ui.Error("é‡ç½®å¤±è´¥: %v", err)
			return
		}
		ui.Success("å·²é‡ç½®è§„åˆ™")
	}

	if resetHistory {
		if !confirmReset("ç¡®è®¤é‡ç½®å†å²è®°å½•?") {
			return
		}
		db.ResetHistory()
		db.ResetVectors()
		ui.Success("å·²é‡ç½®å†å²")
	}

	if !resetRules && !resetHistory && !resetAll {
		cmd.Help()
	}
}

func confirmReset(prompt string) bool {
	fmt.Printf("%s %s [y/N]: ", ui.Yellow("âš "), prompt)
	reader := bufio.NewReader(os.Stdin)
	input, _ := reader.ReadString('\n')
	input = strings.TrimSpace(strings.ToLower(input))
	return input == "y"
}
```

### `cmd/version.go`

```go
package cmd

import (
	"fmt"

	"github.com/spf13/cobra"

	"filo/internal/config"
	"filo/internal/ui"
)

var versionCmd = &cobra.Command{
	Use:   "version",
	Short: "ç‰ˆæœ¬ä¿¡æ¯",
	Run: func(cmd *cobra.Command, args []string) {
		ui.Banner()
		fmt.Printf("  ç‰ˆæœ¬: %s\n", config.Version)
		fmt.Printf("  ä¸»é¡µ: https://github.com/lynx-lee/filo\n")
		fmt.Println()
	},
}

func init() {
	rootCmd.AddCommand(versionCmd)
}
```

---

## å››ã€Makefile

```makefile
APP_NAME := filo
VERSION := 2.0.0
BUILD_TIME := $(shell date +%Y%m%d)
LDFLAGS := -ldflags="-s -w -X filo/internal/config.Version=$(VERSION)"

.PHONY: all build clean install test run

# é»˜è®¤æ„å»º
all: build

# å½“å‰å¹³å°æ„å»º
build:
	@echo "ğŸ”¨ Building $(APP_NAME)..."
	@go build $(LDFLAGS) -o bin/$(APP_NAME) .
	@echo "âœ… Build complete: bin/$(APP_NAME)"

# æ‰€æœ‰å¹³å°æ„å»º
build-all: build-darwin build-linux build-windows
	@echo "âœ… All platforms built"

build-darwin:
	@echo "ğŸ Building for macOS..."
	@CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build $(LDFLAGS) -o bin/$(APP_NAME)-mac-amd64 .
	@CGO_ENABLED=0 GOOS=darwin GOARCH=arm64 go build $(LDFLAGS) -o bin/$(APP_NAME)-mac-arm64 .

build-linux:
	@echo "ğŸ§ Building for Linux..."
	@CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build $(LDFLAGS) -o bin/$(APP_NAME)-linux-amd64 .
	@CGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build $(LDFLAGS) -o bin/$(APP_NAME)-linux-arm64 .

build-windows:
	@echo "ğŸªŸ Building for Windows..."
	@CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build $(LDFLAGS) -o bin/$(APP_NAME)-windows.exe .

# å®‰è£…åˆ°ç³»ç»Ÿ
install: build
	@echo "ğŸ“¦ Installing to /usr/local/bin..."
	@sudo cp bin/$(APP_NAME) /usr/local/bin/
	@echo "âœ… Installed! Run 'filo' to start"

# æ¸…ç†
clean:
	@rm -rf bin/
	@echo "ğŸ§¹ Cleaned"

# æµ‹è¯•
test:
	@go test ./... -v

# å¼€å‘è¿è¡Œ
run:
	@go run . ~/Downloads -n

# åˆå§‹åŒ–ä¾èµ–
deps:
	@go mod tidy
	@echo "âœ… Dependencies ready"

# å¸®åŠ©
help:
	@echo "filo - æ–‡ä»¶æ™ºç†"
	@echo ""
	@echo "æ„å»ºå‘½ä»¤:"
	@echo "  make build      æ„å»ºå½“å‰å¹³å°"
	@echo "  make build-all  æ„å»ºæ‰€æœ‰å¹³å°"
	@echo "  make install    å®‰è£…åˆ°ç³»ç»Ÿ"
	@echo "  make clean      æ¸…ç†æ„å»ºæ–‡ä»¶"
	@echo ""
	@echo "å¼€å‘å‘½ä»¤:"
	@echo "  make run        å¼€å‘æµ‹è¯•è¿è¡Œ"
	@echo "  make test       è¿è¡Œæµ‹è¯•"
	@echo "  make deps       æ›´æ–°ä¾èµ–"
```

---

## äº”ã€README.md

````markdown
# Filo - æ–‡ä»¶æ™ºç†

```
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
  â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
  â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• 
  
  æ–‡ä»¶æ™ºç† Â· è¶Šç”¨è¶Šæ‡‚ä½ 
```

Filo æ˜¯ä¸€ä¸ªåŸºäºæœ¬åœ° AI çš„æ™ºèƒ½æ–‡ä»¶æ•´ç†å·¥å…·ï¼Œèƒ½å¤Ÿå­¦ä¹ ä½ çš„æ•´ç†ä¹ æƒ¯ï¼Œè¶Šç”¨è¶Šæ™ºèƒ½ã€‚

## âœ¨ ç‰¹æ€§

- ğŸ§  **æœ¬åœ° AI** - ä½¿ç”¨ Ollama è¿è¡Œæœ¬åœ°å¤§æ¨¡å‹ï¼Œæ•°æ®ä¸å‡ºé—¨
- ğŸ“š **æ™ºèƒ½å­¦ä¹ ** - è‡ªåŠ¨è®°ä½ä½ çš„æ•´ç†åå¥½ï¼Œè¶Šç”¨è¶Šå‡†ç¡®
- ğŸš€ **æé€Ÿå“åº”** - ç›¸ä¼¼æ–‡ä»¶æ¯«ç§’çº§è¯†åˆ«ï¼Œæ— éœ€é‡å¤ç­‰å¾…
- ğŸ¯ **è¯­ä¹‰ç†è§£** - çœŸæ­£ç†è§£æ–‡ä»¶å«ä¹‰ï¼Œä¸åªæ˜¯çœ‹æ‰©å±•å
- ğŸ’¡ **äº¤äº’çº é”™** - åˆ†ç±»ä¸æ»¡æ„å¯éšæ—¶ä¿®æ­£ï¼Œç³»ç»Ÿç«‹å³å­¦ä¼š

## ğŸ“¦ å®‰è£…

### æ–¹å¼ä¸€ï¼šä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬

ä» [Releases](https://github.com/lynx/filo/releases) ä¸‹è½½å¯¹åº”å¹³å°çš„å¯æ‰§è¡Œæ–‡ä»¶ã€‚

### æ–¹å¼äºŒï¼šä»æºç ç¼–è¯‘

```bash
git clone https://github.com/lynx-lee/filo.git
cd filo
make build
make install
```

### é¦–æ¬¡é…ç½®

```bash
# è¿è¡Œå®‰è£…å‘å¯¼ï¼ˆå®‰è£… Ollama å’Œæ¨¡å‹ï¼‰
filo setup
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```bash
# é¢„è§ˆæ•´ç†æ•ˆæœï¼ˆæ¨èé¦–æ¬¡ä½¿ç”¨ï¼‰
filo ~/Downloads -n

# æ‰§è¡Œæ•´ç†
filo ~/Downloads

# è¯¦ç»†è¾“å‡ºæ¨¡å¼
filo ~/Downloads -v

# äº¤äº’å¼å®¡æŸ¥ï¼ˆä½ç½®ä¿¡åº¦æ–‡ä»¶éœ€ç¡®è®¤ï¼‰
filo ~/Downloads -i

# æŒ‡å®šç›®æ ‡ç›®å½•
filo ~/Downloads -t ~/Documents/Sorted
```

### å…¶ä»–å‘½ä»¤

```bash
# æŸ¥çœ‹å­¦ä¹ ç»Ÿè®¡
filo stats

# æ‰«ææ–‡ä»¶å¤¹ç»Ÿè®¡
filo scan ~/Downloads

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
filo models

# é‡ç½®å­¦ä¹ æ•°æ®
filo reset --all
filo reset --rules
filo reset --history

# æŸ¥çœ‹ç‰ˆæœ¬
filo version
```

### å‘½ä»¤é€‰é¡¹

| é€‰é¡¹ | ç®€å†™ | è¯´æ˜ |
|------|------|------|
| `--target` | `-t` | æŒ‡å®šç›®æ ‡ç›®å½• |
| `--dry-run` | `-n` | é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ç§»åŠ¨æ–‡ä»¶ |
| `--verbose` | `-v` | è¯¦ç»†è¾“å‡º |
| `--interactive` | `-i` | äº¤äº’å¼å®¡æŸ¥æ¨¡å¼ |
| `--model` | `-m` | æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ |
| `--no-learning` | | ç¦ç”¨å­¦ä¹ åŠŸèƒ½ |

## ğŸ§  å­¦ä¹ æœºåˆ¶

Filo ä¼šåœ¨ä»¥ä¸‹æƒ…å†µå­¦ä¹ ä½ çš„åå¥½ï¼š

1. **è‡ªåŠ¨å­¦ä¹ ** - æ¯æ¬¡åˆ†ç±»åè‡ªåŠ¨è®°å½•
2. **ç¡®è®¤å­¦ä¹ ** - æ‰§è¡Œæ•´ç†æ—¶è®°å½•ä¸ºå·²ç¡®è®¤ï¼Œæƒé‡æ›´é«˜
3. **çº æ­£å­¦ä¹ ** - äº¤äº’æ¨¡å¼ä¸‹çš„ä¿®æ­£ä¼šè¢«ä¼˜å…ˆå­¦ä¹ 

```
é¦–æ¬¡ä½¿ç”¨ â”€â”€â†’ å®Œå…¨ä¾èµ– AIï¼Œé€Ÿåº¦è¾ƒæ…¢
  â†“
æŒç»­ä½¿ç”¨ â”€â”€â†’ ç›¸ä¼¼æ–‡ä»¶ä»è®°å¿†è·å–ï¼Œé€Ÿåº¦åŠ å¿«
  â†“
é•¿æœŸä½¿ç”¨ â”€â”€â†’ å¤§éƒ¨åˆ†æ–‡ä»¶æ¯«ç§’çº§åˆ†ç±»ï¼Œåªæœ‰æ–°ç±»å‹æ‰éœ€è¦ AI
```

## ğŸ“Š æ€§èƒ½å‚è€ƒ

| é˜¶æ®µ | 100ä¸ªæ–‡ä»¶è€—æ—¶ | ä»è®°å¿†è·å–æ¯”ä¾‹ |
|------|--------------|--------------|
| é¦–æ¬¡ä½¿ç”¨ | ~60ç§’ | 0% |
| ä½¿ç”¨ä¸€å‘¨ | ~25ç§’ | ~60% |
| ä½¿ç”¨ä¸€æœˆ | ~5ç§’ | ~90% |

## ğŸ”§ é…ç½®

é…ç½®æ–‡ä»¶ä½äº `~/.filo/config.json`

```json
{
  "llm_model": "qwen2.5:7b",
  "temperature": 0.3,
  "enable_learning": true,
  "similarity_threshold": 0.85,
  "batch_size": 15
}
```

## ğŸ“‹ æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | å‚æ•°é‡ | å†…å­˜éœ€æ±‚ | ä¸­æ–‡æ”¯æŒ | æ¨èåº¦ |
|------|--------|---------|---------|--------|
| qwen2.5:7b | 7B | 6-8GB | â­â­â­â­â­ | ğŸ† é¦–é€‰ |
| qwen2.5:3b | 3B | 3-4GB | â­â­â­â­ | è½»é‡é¦–é€‰ |
| llama3.1:8b | 8B | 8-10GB | â­â­â­ | æ¨è |
| mistral:7b | 7B | 6-8GB | â­â­ | å¯é€‰ |

## ğŸ“„ è®¸å¯è¯

MIT License
````

---

## å…­ã€install.sh (ä¸€é”®å®‰è£…è„šæœ¬)

```bash
#!/bin/bash

set -e

echo ""
echo "  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— "
echo "  â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—"
echo "  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘"
echo "  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘"
echo "  â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•"
echo "  â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• "
echo ""
echo "  æ–‡ä»¶æ™ºç† Â· è¶Šç”¨è¶Šæ‡‚ä½ "
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# æ£€æµ‹ç³»ç»Ÿ
OS=$(uname -s)
ARCH=$(uname -m)

echo ""
echo "ğŸ“ ç³»ç»Ÿ: $OS $ARCH"

# ç¡®å®šä¸‹è½½æ–‡ä»¶å
case "$OS" in
    Darwin)
        case "$ARCH" in
            arm64) BINARY="filo-mac-arm64" ;;
            x86_64) BINARY="filo-mac-amd64" ;;
            *) echo "âŒ ä¸æ”¯æŒçš„æ¶æ„: $ARCH"; exit 1 ;;
        esac
        ;;
    Linux)
        case "$ARCH" in
            aarch64) BINARY="filo-linux-arm64" ;;
            x86_64) BINARY="filo-linux-amd64" ;;
            *) echo "âŒ ä¸æ”¯æŒçš„æ¶æ„: $ARCH"; exit 1 ;;
        esac
        ;;
    *)
        echo "âŒ ä¸æ”¯æŒçš„ç³»ç»Ÿ: $OS"
        exit 1
        ;;
esac

# ä¸‹è½½åœ°å€ï¼ˆæ›¿æ¢ä¸ºå®é™…åœ°å€ï¼‰
DOWNLOAD_URL="https://github.com/lynx-lee/filo/releases/latest/download/$BINARY"

echo ""
echo "ğŸ“¥ ä¸‹è½½ filo..."

# ä¸‹è½½
INSTALL_DIR="/usr/local/bin"
TMP_FILE="/tmp/filo"

if command -v curl &> /dev/null; then
    curl -fsSL "$DOWNLOAD_URL" -o "$TMP_FILE"
elif command -v wget &> /dev/null; then
    wget -q "$DOWNLOAD_URL" -O "$TMP_FILE"
else
    echo "âŒ éœ€è¦ curl æˆ– wget"
    exit 1
fi

chmod +x "$TMP_FILE"

# å®‰è£…
echo "ğŸ“¦ å®‰è£…åˆ° $INSTALL_DIR..."
sudo mv "$TMP_FILE" "$INSTALL_DIR/filo"

echo ""
echo "âœ… å®‰è£…å®Œæˆï¼"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ä¸‹ä¸€æ­¥ï¼š"
echo ""
echo "  1. è¿è¡Œå®‰è£…å‘å¯¼: filo setup"
echo "  2. é¢„è§ˆæ•´ç†æ•ˆæœ: filo ~/Downloads -n"
echo "  3. æ‰§è¡Œæ•´ç†:     filo ~/Downloads"
echo ""
```

---

## ä¸ƒã€å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†/åˆ›å»ºé¡¹ç›®
mkdir filo && cd filo

# 2. åˆå§‹åŒ– Go æ¨¡å—
go mod init filo
go mod tidy

# 3. ç¼–è¯‘
make build

# 4. å®‰è£…åˆ°ç³»ç»Ÿ
make install

# 5. è¿è¡Œè®¾ç½®å‘å¯¼
filo setup

# 6. å¼€å§‹ä½¿ç”¨
filo ~/Downloads -n    # é¢„è§ˆ
filo ~/Downloads       # æ‰§è¡Œ
```

---

è¿™å°±æ˜¯ **Filo** çš„å®Œæ•´è®¾è®¡æ–¹æ¡ˆï¼Œä¸€ä¸ªç®€æ´ä¼˜é›…ã€è¶Šç”¨è¶Šæ™ºèƒ½çš„æœ¬åœ° AI æ–‡ä»¶æ•´ç†å·¥å…·ï¼ ğŸ‰